# /media/bodega/procesador/web_app/app.py
import os
import json
import uuid
import redis
import subprocess
import threading
import logging
import traceback
from datetime import datetime
from flask import Flask, render_template, request, jsonify, redirect, url_for, flash, session
from werkzeug.utils import secure_filename
from sqlalchemy import create_engine, text
import pytz
from functools import wraps
import requests # <-- ADDED FOR GEOLOCATION

# --- LOGGING SETUP BLOCK ---
log_dir = '/media/bodega/procesador/logs'
os.makedirs(log_dir, exist_ok=True)
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - [FlaskWebApp] - %(message)s', handlers=[logging.FileHandler(os.path.join(log_dir, 'web_app.log')), logging.StreamHandler()])
logger = logging.getLogger(__name__)

# --- CONFIGURACIÓN DEL LOG DE AUDITORÍA ---
audit_log_path = os.path.join(log_dir, 'search_audit.log')
audit_handler = logging.FileHandler(audit_log_path)
audit_handler.setFormatter(logging.Formatter('%(asctime)s - %(message)s'))

audit_logger = logging.getLogger('search_audit')
audit_logger.setLevel(logging.INFO)
audit_logger.addHandler(audit_handler)
audit_logger.propagate = False
# --- FIN DEL BLOQUE DE AUDITORÍA ---

# --- FLASK APP INITIALIZATION ---
app = Flask(__name__, template_folder='/media/bodega/procesador/templates')
app.secret_key = 'your-secret-key-change-this-to-something-secure'
app.config['TEMPLATES_AUTO_RELOAD'] = True

# --- CONFIGURATION & GLOBALS ---
ADMIN_PASSWORD = 'dejameacuerdo'
UPLOAD_FOLDER = '/media/bodega/procesador/uploads'
SAFE_STORAGE = '/media/bodega/procesador/safe_storage'
ALLOWED_EXTENSIONS = {'txt', 'xlsx', 'csv'}
redis_client = redis.Redis(host='localhost', port=6379, db=0, decode_responses=True)

# --- NEW: IP WHITELIST ---
# Add your office, home, or any other authorized public IP addresses here.
ALLOWED_IPS = ['127.0.0.1', '192.168.1.47', '186.115.102.248']


# --- HELPER & AUTH FUNCTIONS ---
def allowed_file(filename):
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

def is_admin_logged_in():
    return session.get('admin_logged_in', False)

def require_admin():
    def decorator(f):
        @wraps(f)
        def wrapper(*args, **kwargs):
            if not is_admin_logged_in():
                return redirect(url_for('admin_login'))
            return f(*args, **kwargs)
        return wrapper
    return decorator

def get_real_ip():
    if 'CF-Connecting-IP' in request.headers:
        return request.headers['CF-Connecting-IP']
    return request.remote_addr

# --- UPDATED SECURITY DECORATOR ---
def apply_security_rules(func):
    """
    Decorator that handles IP whitelisting, updated working hours, and geolocation logging.
    """
    @wraps(func)
    def decorated_function(*args, **kwargs):
        ip_address = get_real_ip()
        
        # 1. IP Whitelist Check
        if ip_address not in ALLOWED_IPS:
            audit_logger.critical(f"BLOCKED (Unauthorized IP) - IP: {ip_address}")
            if request.path.startswith('/api/'):
                 return jsonify({'error': 'Access from your IP address is not permitted.'}), 403
            else:
                 return "Access Denied: Your IP address is not authorized.", 403

        # 2. Updated Working Hours Check
        colombia_tz = pytz.timezone('America/Bogota')
        now = datetime.now(colombia_tz)
        is_weekday_hours = (0 <= now.weekday() <= 4) and (8 <= now.hour < 18)
        is_saturday_hours = (now.weekday() == 5) and (8 <= now.hour < 13)

        user_agent = request.headers.get('User-Agent', 'Unknown')
        searched_number = request.args.get('number', 'N/A')
        
        # 3. Geolocation Logging
        geolocation = "Unknown"
        try:
            geo_response = requests.get(f"https://ipapi.co/{ip_address}/json/", timeout=2)
            if geo_response.status_code == 200:
                geo_data = geo_response.json()
                city = geo_data.get('city', 'N/A')
                country = geo_data.get('country_name', 'N/A')
                geolocation = f"{city}, {country}"
        except Exception as e:
            logger.warning(f"Could not fetch geolocation for IP {ip_address}: {e}")

        # Apply Rules and Log
        if is_weekday_hours or is_saturday_hours:
            response = func(*args, **kwargs)
            if response.is_json and response.status_code == 200:
                audit_logger.info(f"SUCCESS - IP: {ip_address}, Geo: {geolocation}, Searched: {searched_number}, Client: {user_agent}")
            return response
        else:
            audit_logger.warning(f"BLOCKED (Out of Hours) - IP: {ip_address}, Geo: {geolocation}, Attempted Search: {searched_number}, Client: {user_agent}")
            if request.path.startswith('/api/'):
                return jsonify({'error': 'Access denied: Outside working hours'}), 403
            else:
                return render_template('fuera_de_horario.html'), 403
            
    return decorated_function

# --- PROCESSING & FILE MANAGEMENT ---
def move_to_safe_storage(uploaded_file_path, file_type):
    filename = os.path.basename(uploaded_file_path)
    if file_type == 'txt':
        safe_folder = os.path.join(SAFE_STORAGE, 'txt_files')
    else: # xlsx, csv
        date_folder = datetime.now().strftime('%Y-%m-%d')
        safe_folder = os.path.join(SAFE_STORAGE, 'spreadsheet_files', date_folder)
    os.makedirs(safe_folder, exist_ok=True)
    safe_path = os.path.join(safe_folder, filename)
    os.rename(uploaded_file_path, safe_path)
    return safe_path

def start_processing(job_id, file_path, file_type):
    try:
        script_path = None
        if file_type == 'txt':
            script_path = '/media/bodega/procesador/scripts/process_txt.py'
        elif file_type == 'suppression_xlsx':
            script_path = '/media/bodega/procesador/scripts/process_xlsx.py'
        elif file_type == 'suppression_csv':
            script_path = '/media/bodega/procesador/scripts/process_csv.py'
        elif file_type == 'sales_xlsx':
            script_path = '/media/bodega/procesador/scripts/process_sales.py'
        else:
            logger.error(f"Unknown file type for processing: {file_type}")
            return

        venv_python = '/media/bodega/procesador/bin/python'
        logger.info(f"Starting processing: {script_path} for job {job_id}")
        
        result = subprocess.run([venv_python, script_path, '--file-path', file_path, '--job-id', job_id], capture_output=True, text=True)
        
        if result.returncode != 0:
             logger.error(f"Script for job {job_id} failed. STDERR: {result.stderr}")
        else:
             logger.info(f"Script for job {job_id} completed. STDOUT: {result.stdout}")

    except Exception as e:
        logger.error(f"Failed to start processing thread for job {job_id}: {e}")
        job_data = json.loads(redis_client.get(f'job:{job_id}') or '{}')
        job_data['status'] = 'failed'
        job_data['error'] = f"Failed to start script: {e}"
        redis_client.setex(f'job:{job_id}', 3600, json.dumps(job_data))

# --- STANDARD PAGE ROUTES ---
@app.route('/')
def index():
    return render_template('index.html')

@app.route('/admin-login', methods=['GET', 'POST'])
def admin_login():
    if request.method == 'POST':
        if request.form.get('password') == ADMIN_PASSWORD:
            session['admin_logged_in'] = True
            return redirect(url_for('admin'))
        else:
            flash('Invalid password.', 'error')
    return render_template('admin_login.html')

@app.route('/admin-logout')
def admin_logout():
    session.pop('admin_logged_in', None)
    return redirect(url_for('index'))

@app.route('/admin')
@require_admin()
def admin():
    recent_jobs = []
    try:
        job_keys = sorted(redis_client.keys('job:*'), reverse=True)[:10]
        for key in job_keys:
            recent_jobs.append(json.loads(redis_client.get(key) or '{}'))
    except Exception as e:
        logger.error(f"Could not fetch recent jobs from Redis: {e}")
    return render_template('admin.html', recent_jobs=recent_jobs)

@app.route('/dnc')
def dnc_search():
    return render_template('dnc_search.html')

@app.route('/suppression')
def suppression_search():
    return render_template('suppression_search.html')
    
@app.route('/sales-search')
def sales_search():
    return render_template('sales_search.html')

@app.route('/progress/<job_id>')
@require_admin()
def progress(job_id):
    return render_template('progress.html', job_id=job_id)

# --- API & BACKGROUND ROUTES ---
@app.route('/upload', methods=['POST'])
@require_admin()
def upload_file():
    if 'file' not in request.files or request.files['file'].filename == '':
        flash('No file selected.', 'error')
        return redirect(url_for('admin'))
    
    file = request.files['file']
    file_type = request.form.get('file_type')
    
    if not file_type:
        flash('Please select a file type.', 'error')
        return redirect(url_for('admin'))
        
    if file and allowed_file(file.filename):
        job_id = str(uuid.uuid4())
        filename = secure_filename(file.filename)
        upload_path = os.path.join(UPLOAD_FOLDER, f"{job_id}_{filename}")
        file.save(upload_path)
        safe_path = move_to_safe_storage(upload_path, file_type)
        
        job_data = {'job_id': job_id, 'filename': filename, 'file_type': file_type, 'status': 'queued', 'started_at': datetime.now().isoformat()}
        redis_client.setex(f'job:{job_id}', 3600, json.dumps(job_data))
        
        thread = threading.Thread(target=start_processing, args=(job_id, safe_path, file_type))
        thread.daemon = True
        thread.start()
        
        return redirect(url_for('progress', job_id=job_id))
    
    flash('Invalid file type.', 'error')
    return redirect(url_for('admin'))

@app.route('/api/progress/<job_id>')
def api_progress(job_id):
    job_data = redis_client.get(f'job:{job_id}')
    return jsonify(json.loads(job_data)) if job_data else ({'status': 'not_found'}, 404)

@app.route('/admin/clear-database', methods=['POST'])
@require_admin()
def clear_database():
    try:
        engine = create_engine('postgresql://anakin0:dejameacuerdo@localhost:5432/dnc_processor')
        with engine.connect() as conn:
            conn.execute(text("DROP TABLE IF EXISTS dnc_records;"))
            conn.execute(text("DROP TABLE IF EXISTS suppression_records;"))
            conn.execute(text("DROP TABLE IF EXISTS sales_records;"))
            conn.commit()
        flash('Successfully cleared all data tables.', 'success')
    except Exception as e:
        flash(f'Error clearing database: {e}', 'error')
    return redirect(url_for('admin'))

@app.route('/admin/database-stats')
@require_admin()
def database_stats():
    dnc_count, suppression_count, sales_count = 0, 0, 0
    state_breakdown = []
    try:
        engine = create_engine('postgresql://anakin0:dejameacuerdo@localhost:5432/dnc_processor')
        with engine.connect() as conn:
            try:
                dnc_count = conn.execute(text("SELECT COUNT(*) FROM dnc_records")).scalar_one()
                state_results = conn.execute(text("SELECT state, COUNT(*) as count FROM dnc_records GROUP BY state ORDER BY state")).fetchall()
                state_breakdown = [{'state': row.state, 'count': row.count} for row in state_results]
            except: pass
            try:
                suppression_count = conn.execute(text("SELECT COUNT(*) FROM suppression_records")).scalar_one()
            except: pass
            try:
                sales_count = conn.execute(text("SELECT COUNT(*) FROM sales_records")).scalar_one()
            except: pass
        
        return jsonify({
            'total_records': dnc_count + suppression_count + sales_count,
            'record_counts': [
                {'type': 'DNC Records', 'count': dnc_count},
                {'type': 'Suppression Records', 'count': suppression_count},
                {'type': 'Sales Records', 'count': sales_count}
            ],
            'state_breakdown': state_breakdown
        })
    except Exception as e:
        logger.error(f"Database stats error: {e}")
        return jsonify({'error': str(e)}), 500
    
@app.route('/api/search')
@apply_security_rules
def api_search():
    number = request.args.get('number');
    if not number: return jsonify({'error': 'Number is required'}), 400
    try:
        search_number = int(''.join(filter(str.isdigit, number)))
        engine = create_engine('postgresql://anakin0:dejameacuerdo@localhost:5432/dnc_processor')
        with engine.connect() as conn:
            result = conn.execute(text("SELECT number, state FROM dnc_records WHERE number = :number"), {'number': search_number}).fetchone()
        if result:
            return jsonify({'found': True, 'number': str(result.number), 'state': result.state})
        else:
            return jsonify({'found': False, 'number': search_number})
    except Exception as e:
        logger.error(f"DNC-only search error: {e}")
        return jsonify({'error': 'Server error'}), 500

@app.route('/api/suppression-search')
@apply_security_rules
def api_suppression_search():
    number = request.args.get('number');
    if not number: return jsonify({'error': 'Number is required'}), 400
    try:
        search_number = int(''.join(filter(str.isdigit, number)))
        engine = create_engine('postgresql://anakin0:dejameacuerdo@localhost:5432/dnc_processor')
        dnc_result, suppression_result = None, None
        with engine.connect() as conn:
            try:
                dnc_record = conn.execute(text("SELECT number, state FROM dnc_records WHERE number = :number"), {'number': search_number}).fetchone()
                if dnc_record: dnc_result = {'found': True, 'state': dnc_record.state}
            except: pass
            try:
                supp_record = conn.execute(text("SELECT number, commodity FROM suppression_records WHERE number = :number"), {'number': search_number}).fetchone()
                if supp_record: suppression_result = {'found': True, 'commodity': supp_record.commodity}
            except: pass
        return jsonify({'found': bool(dnc_result or suppression_result), 'search_number': str(search_number), 'dnc_status': dnc_result, 'suppression_status': suppression_result})
    except Exception as e:
        logger.error(f"Combined search error: {e}\n{traceback.format_exc()}")
        return jsonify({'error': str(e)}), 500

@app.rou